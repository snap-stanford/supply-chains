{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch as t\n",
    "import numpy as np\n",
    "\n",
    "from memory_module import TGNPLMemory\n",
    "from msg_func import TGNPLMessage\n",
    "from msg_agg import *\n",
    "\n",
    "from neighbor_loader import LastNeighborLoader, LastNeighborLoaderTGNPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TGNPLMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "num_prods = 2\n",
    "raw_msg_dim = 1\n",
    "state_dim = 10\n",
    "time_dim = 1\n",
    "message_module = TGNPLMessage(raw_msg_dim, state_dim+num_prods, time_dim)\n",
    "aggregator_module = MeanAggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test initialization\n",
    "mem = TGNPLMemory(num_nodes,\n",
    "        num_prods,\n",
    "        raw_msg_dim,\n",
    "        state_dim,\n",
    "        time_dim,\n",
    "        message_module,\n",
    "        aggregator_module,\n",
    "        state_updater_cell=\"gru\",\n",
    "        use_inventory=True,\n",
    "        debt_penalty=10,\n",
    "        consumption_reward=5,\n",
    "        debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# before any interactions have been added\n",
    "np.random.seed(0)\n",
    "n_id = np.random.choice(num_nodes, size=5, replace=False)\n",
    "n_id = t.from_numpy(n_id)\n",
    "print(n_id)\n",
    "memory, last_update, loss = mem(n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try adding interactions\n",
    "# expectation: \n",
    "# 1) get_updated_memory will print 6 nodes, but memories shouldn't be updated yet\n",
    "# 2) _update_msg_store should update all three msg stores\n",
    "src = t.Tensor([0, 0, 1, 2]).long()\n",
    "dst = t.Tensor([3, 3, 3, 0]).long()\n",
    "prod = t.Tensor([8, 8, 8, 9]).long()\n",
    "time = t.Tensor(np.ones(4)).long()\n",
    "raw_msg = t.Tensor([10, 20, 5, 13]).reshape(-1, 1)\n",
    "mem.update_state(src, dst, prod, time, raw_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mem.msg_s_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mem.msg_d_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mem.msg_p_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get memory again - only nodes with interactions should've changed\n",
    "n_id = t.from_numpy(np.arange(num_nodes))\n",
    "memory, last_update, loss = mem(n_id)  # test .forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 and 9, same state, different inventory\n",
    "# 2 supplied product 9\n",
    "# product 9 has no inventory\n",
    "memory[[2,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 and 8, same state, different inventory\n",
    "# 3 received exactly 35 of product 8\n",
    "# product 8 has no inventory\n",
    "memory[[3,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# should be unaffected\n",
    "memory[[4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should only be updated for nodes in transactions\n",
    "last_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test attention weight learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 6\n",
    "num_prods = 3\n",
    "raw_msg_dim = 1\n",
    "state_dim = 2\n",
    "time_dim = 1\n",
    "message_module = TGNPLMessage(raw_msg_dim, state_dim+num_prods, time_dim)\n",
    "aggregator_module = MeanAggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_msg_dim + (3 * memory_dim) + time_dim\n",
    "message_module.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_id = t.arange(0, num_nodes).long()\n",
    "print(n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = TGNPLMemory(num_nodes,\n",
    "        num_prods,\n",
    "        raw_msg_dim,\n",
    "        state_dim,\n",
    "        time_dim,\n",
    "        message_module,\n",
    "        aggregator_module,\n",
    "        state_updater_cell=\"gru\",\n",
    "        use_inventory=True,\n",
    "        debt_penalty=10,\n",
    "        consumption_reward=5,\n",
    "        debug=False)\n",
    "opt = t.optim.Adam(mem.parameters())\n",
    "for name, param in mem.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.autograd.set_detect_anomaly(True)\n",
    "for i in range(1, 31):\n",
    "#     opt.zero_grad()\n",
    "    if (i % 2) == 0:\n",
    "        # 1 sells 5 to 2\n",
    "        src = t.Tensor([1]).long()\n",
    "        dst = t.Tensor([2]).long()\n",
    "        prod = t.Tensor([5]).long()\n",
    "        time = t.Tensor([i]).long()\n",
    "        raw_msg = t.Tensor([1]).reshape(-1, 1)\n",
    "    else:\n",
    "        # 1 buys 3 and 4 from 0\n",
    "        src = t.Tensor([0, 0]).long()\n",
    "        dst = t.Tensor([1, 1]).long()\n",
    "        prod = t.Tensor([3, 4]).long()\n",
    "        time = t.Tensor([i, i]).long()\n",
    "        raw_msg = t.Tensor([2, 4]).reshape(-1, 1)\n",
    "\n",
    "    print('iter', i)\n",
    "    mem.update_state(src, dst, prod, time, raw_msg)\n",
    "    memory, last_update, loss = mem(n_id)\n",
    "    print('loss', loss)\n",
    "    prod_emb = mem.memory[mem.num_firms:, :mem.state_dim]\n",
    "    # prod_emb = t.ones(mem.num_prods, mem.state_dim)\n",
    "    output_emb = mem.output_l(prod_emb)  # num_products x emb_dim\n",
    "    input_emb = mem.input_l(prod_emb)  # num_products x emb_dim\n",
    "    att_weights = output_emb @ input_emb.T  # num_products x num_products\n",
    "    att_weights = t.nn.ReLU(inplace=False)(att_weights)\n",
    "    print('att weights', att_weights)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Neighbor Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_loader = LastNeighborLoaderTGNPL(9, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 2])\n",
      "torch.Size([9, 2])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# Test init\n",
    "print(neighbor_loader.neighbors.shape)\n",
    "print(neighbor_loader.e_id.shape)\n",
    "print(neighbor_loader._assoc.shape)\n",
    "self = neighbor_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) tensor([[              6, 159321811882214],\n",
      "        [              7, 158772056065462],\n",
      "        [              8,  88214333292640],\n",
      "        [              6,       110377216],\n",
      "        [              7,               0],\n",
      "        [              8,       112948880],\n",
      "        [              3,               0],\n",
      "        [              4,               1],\n",
      "        [              5,               2]])\n"
     ]
    }
   ],
   "source": [
    "# Test insert\n",
    "src = torch.Tensor([0, 1, 2]).to(torch.long)\n",
    "dst = torch.Tensor([3, 4, 5]).to(torch.long)\n",
    "prod = torch.Tensor([6, 7, 8]).to(torch.long)\n",
    "\n",
    "nodes = torch.cat([prod, src, prod, dst], dim=0)\n",
    "n_id = nodes.unique()\n",
    "neighbor_loader.insert(src, dst, prod)\n",
    "\n",
    "print(n_id, self.neighbors[n_id]) # This is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) torch.Size([9])\n",
      "tensor([[6, 7, 8, 6, 7, 8, 3, 0, 4, 1, 5, 2],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 8]]) torch.Size([2, 12])\n",
      "tensor([0, 1, 2, 3, 4, 5, 3, 0, 4, 1, 5, 2]) torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# Test _call_\n",
    "f_id = torch.cat([src, dst]).unique()\n",
    "p_id = torch.cat([prod]).unique()\n",
    "\n",
    "n_id, edge_index, e_id = neighbor_loader(f_id, p_id)\n",
    "\n",
    "# Ground truth: 6 edges 0-6, 3-6, 1-7, 4-7, 2-8, 5-8\n",
    "print(n_id, n_id.shape)\n",
    "print(edge_index, edge_index.shape)\n",
    "print(e_id, e_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 6]) tensor([[6, 6],\n",
      "        [6, 7],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Test insert\n",
    "src = torch.Tensor([0]).to(torch.long)\n",
    "dst = torch.Tensor([1]).to(torch.long)\n",
    "prod = torch.Tensor([6]).to(torch.long)\n",
    "\n",
    "nodes = torch.cat([prod, src, prod, dst], dim=0)\n",
    "n_id = nodes.unique()\n",
    "neighbor_loader.insert(src, dst, prod)\n",
    "\n",
    "print(n_id, self.neighbors[n_id]) # This is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 6, 7]) torch.Size([4])\n",
      "tensor([[2, 2, 2, 3, 1, 0],\n",
      "        [0, 0, 1, 1, 2, 2]]) torch.Size([2, 6])\n",
      "tensor([6, 0, 7, 1, 7, 6]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Test _call_\n",
    "f_id = torch.cat([src, dst]).unique()\n",
    "p_id = torch.cat([prod]).unique()\n",
    "\n",
    "n_id, edge_index, e_id = neighbor_loader(f_id, p_id)\n",
    "\n",
    "# Ground truth: 6 edges 0-6, 1-6, 1-7\n",
    "print(n_id, n_id.shape)\n",
    "print(edge_index, edge_index.shape)\n",
    "print(e_id, e_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgb_env",
   "language": "python",
   "name": "tgb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
